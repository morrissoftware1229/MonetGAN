{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project 4 - Group 17: Creates artwork using a cycle GAN similar to Monet's style\n\n\n> Charles Morris ( cmorris95 )\n> Ryan Smith ( rsmit300 )\n> Jeffrey Fortune ( jfortun3 )\n> Kyle Shannon ( kshannon5 )\n> Simon Boka ( sboka )\n","metadata":{}},{"cell_type":"markdown","source":"**Requirements**","metadata":{}},{"cell_type":"code","source":"!pip install opencv-contrib-python Pillow matplotlib torch torchvision pytorch-fid","metadata":{"id":"GDzEqekH-IJr","outputId":"1218b323-af8e-4a76-9167-5f58aee826e8","execution":{"iopub.status.busy":"2023-12-12T02:22:34.230474Z","iopub.execute_input":"2023-12-12T02:22:34.231436Z","iopub.status.idle":"2023-12-12T02:22:46.797362Z","shell.execute_reply.started":"2023-12-12T02:22:34.231391Z","shell.execute_reply":"2023-12-12T02:22:46.796269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport json\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom PIL import Image\nfrom time import time\nimport shutil\nimport zipfile\nimport itertools\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid, save_image\nfrom pytorch_fid import fid_score","metadata":{"id":"wqnueSdd-IJw","execution":{"iopub.status.busy":"2023-12-12T02:22:46.799999Z","iopub.execute_input":"2023-12-12T02:22:46.800820Z","iopub.status.idle":"2023-12-12T02:22:48.703978Z","shell.execute_reply.started":"2023-12-12T02:22:46.800778Z","shell.execute_reply":"2023-12-12T02:22:48.702551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Global Constants**","metadata":{"id":"tMWOUcG1BR0c"}},{"cell_type":"code","source":"BATCH_SIZE = 5\n\nMONET_IMAGES = glob.glob('/kaggle/input/gan-getting-started/monet_jpg/*.jpg')\nTEST_IMAGES = glob.glob('/kaggle/input/gan-getting-started/photo_jpg/*.jpg')\nprint(\"Total Monet Images:\", len(MONET_IMAGES), \"Total Test Images:\", len(TEST_IMAGES))\n\nSAVED_MODEL_PATH = '/kaggle/working/monet_cyclegan_model_final.pth'\nMODEL_CHECKPOINT = '/kaggle/working/monet_cyclegan_model.pth'\nGENERATED_MONET_IMAGES = '/kaggle/working/submission'\nSUBMISSION_FILE = '/kaggle/working/images.zip'\nMETRICS_FILE = '/kaggle/working/monet_cyclegan_metrics.json'\nFID_SCORE_DIRS = ['/kaggle/working/fid_score_real_images', '/kaggle/working/fid_score_generated_images']","metadata":{"id":"ISgEGvedA_9u","outputId":"860096ff-1f0f-420d-f5f1-82e986c73d8b","execution":{"iopub.status.busy":"2023-12-12T02:22:48.711716Z","iopub.execute_input":"2023-12-12T02:22:48.715943Z","iopub.status.idle":"2023-12-12T02:22:48.785568Z","shell.execute_reply.started":"2023-12-12T02:22:48.715881Z","shell.execute_reply":"2023-12-12T02:22:48.784568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Hyperparameters**","metadata":{}},{"cell_type":"code","source":"lr = 0.00014\nbeta1 = 0.5\nbeta2 = 0.999\nn_epoches = 150\ndecay_epoch = 50\ndisplay_epoch = 10","metadata":{"id":"UpwinWaL-IJy","execution":{"iopub.status.busy":"2023-12-12T02:22:48.788406Z","iopub.execute_input":"2023-12-12T02:22:48.789729Z","iopub.status.idle":"2023-12-12T02:22:48.796240Z","shell.execute_reply.started":"2023-12-12T02:22:48.789691Z","shell.execute_reply":"2023-12-12T02:22:48.795149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for CUDA availability and define the Tensor type accordingly\nTensor = torch.Tensor\ndevice = torch.device(\"cpu\")\ncuda_available = torch.cuda.is_available()\nif cuda_available:\n    Tensor = torch.cuda.FloatTensor\n    device = torch.device(\"cuda\")\nprint(f'CUDA Available: {cuda_available}')","metadata":{"id":"qJhSmnZLjn00","outputId":"a2a13d90-cc88-446f-8e33-7d4f473addb9","execution":{"iopub.status.busy":"2023-12-12T02:22:48.798511Z","iopub.execute_input":"2023-12-12T02:22:48.798918Z","iopub.status.idle":"2023-12-12T02:22:48.830555Z","shell.execute_reply.started":"2023-12-12T02:22:48.798876Z","shell.execute_reply":"2023-12-12T02:22:48.829018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, test=False, transforms=None):\n        self.transforms = transforms\n\n        if test:\n            self.monet_dataset = MONET_IMAGES[250:]\n            self.photo_dataset = TEST_IMAGES[250:301]\n        else:\n            self.monet_dataset = MONET_IMAGES[:250]\n            self.photo_dataset = TEST_IMAGES[:250]\n\n    def __len__(self):\n        return min(len(self.monet_dataset), len(self.photo_dataset))\n\n    def __getitem__(self, index):\n        monet_item =  Image.open(self.monet_dataset[index])\n        photo_item =  Image.open(self.photo_dataset[index])\n\n        if self.transforms is not None:\n            monet_item = self.transforms(monet_item)\n            photo_item = self.transforms(photo_item)\n        return photo_item, monet_item ","metadata":{"id":"uGdOvc3G-IJ1","execution":{"iopub.status.busy":"2023-12-12T02:22:48.832661Z","iopub.execute_input":"2023-12-12T02:22:48.833444Z","iopub.status.idle":"2023-12-12T02:22:48.845678Z","shell.execute_reply.started":"2023-12-12T02:22:48.833402Z","shell.execute_reply":"2023-12-12T02:22:48.844766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, in_channels):\n        super(Discriminator, self).__init__()\n        self.scale_factor = 16\n\n        self.model = nn.Sequential(\n            nn.Conv2d(in_channels, 64, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n            nn.InstanceNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, 4, stride=2, padding=1),\n            nn.InstanceNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.ZeroPad2d((1,0,1,0)),\n            nn.Conv2d(512, 1, 4, padding=1),\n        )\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"id":"EA2CRgqJ-IJ7","execution":{"iopub.status.busy":"2023-12-12T02:22:48.846880Z","iopub.execute_input":"2023-12-12T02:22:48.847275Z","iopub.status.idle":"2023-12-12T02:22:48.859245Z","shell.execute_reply.started":"2023-12-12T02:22:48.847246Z","shell.execute_reply":"2023-12-12T02:22:48.858237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels):\n        super(ResidualBlock, self).__init__()\n        self.block = nn.Sequential(\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_channels, in_channels, 3),\n            nn.InstanceNorm2d(in_channels),\n            nn.ReLU(inplace=True),\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_channels, in_channels, 3),\n            nn.InstanceNorm2d(in_channels)\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\nclass GeneratorResNet(nn.Module):\n    def __init__(self, in_channels, num_residual_blocks=9):\n        super(GeneratorResNet, self).__init__()\n\n        self.initial = nn.Sequential(\n            nn.ReflectionPad2d(in_channels),\n            nn.Conv2d(in_channels, 64, 2 * in_channels + 1),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True)\n        )\n\n        self.downsample_blocks = nn.Sequential(\n            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n            nn.InstanceNorm2d(256),\n            nn.ReLU(inplace=True)\n        )\n\n        self.residual_blocks = nn.Sequential(*[ResidualBlock(256) for _ in range(num_residual_blocks)])\n\n        self.upsample_blocks = nn.Sequential(\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(256, 128, 3, stride=1, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Upsample(scale_factor=2),\n            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True)\n        )\n\n        self.output = nn.Sequential(\n            nn.ReflectionPad2d(in_channels),\n            nn.Conv2d(64, in_channels, 2 * in_channels + 1),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        x = self.initial(x)\n        x = self.downsample_blocks(x)\n        x = self.residual_blocks(x)\n        x = self.upsample_blocks(x)\n        return self.output(x)","metadata":{"id":"0z_zQOE8-IJ8","execution":{"iopub.status.busy":"2023-12-12T02:22:48.860523Z","iopub.execute_input":"2023-12-12T02:22:48.860890Z","iopub.status.idle":"2023-12-12T02:22:48.875313Z","shell.execute_reply.started":"2023-12-12T02:22:48.860854Z","shell.execute_reply":"2023-12-12T02:22:48.874327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CycleGAN(nn.Module):\n    def __init__(self, in_channels, num_residual_blocks=9):\n        super(CycleGAN, self).__init__()\n        # Initialize the generator and discriminator models\n        self.monet_generator = GeneratorResNet(in_channels, num_residual_blocks).to(device)\n        self.photo_generator = GeneratorResNet(in_channels, num_residual_blocks).to(device)\n        self.monet_discriminator = Discriminator(in_channels).to(device)\n        self.photo_discriminator = Discriminator(in_channels).to(device)\n\n    def forward(self, photo, monet):\n        with torch.no_grad():\n            fake_monet = self.monet_generator(photo)\n            fake_photo = self.photo_generator(monet)\n        return fake_monet, fake_photo\n\n    def save_model(self, filename):\n        torch.save(self.state_dict(), filename)\n\n    def load_model(self, filename):\n        model_state = torch.load(filename, map_location=device)\n        self.load_state_dict(model_state)\n        self.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:22:48.876543Z","iopub.execute_input":"2023-12-12T02:22:48.876861Z","iopub.status.idle":"2023-12-12T02:22:48.892453Z","shell.execute_reply.started":"2023-12-12T02:22:48.876835Z","shell.execute_reply":"2023-12-12T02:22:48.891438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MonetLoss:\n    def __init__(self, model:CycleGAN) -> None:\n        self.gan_loss = nn.MSELoss().to(device)\n        self.cycle_loss = nn.L1Loss().to(device)\n        self.identity_loss = nn.L1Loss().to(device)\n        self.model = model\n\n\n    def calculate_loss(self, real_photo, real_monet, reconstructed_photo, reconstructed_monet, fake_photo, fake_monet):\n        loss_identity = self.calculate_identity_loss(real_photo, real_monet)\n\n        labeled_fake_monet = self.model.photo_discriminator(fake_monet)\n        labeled_fake_photo = self.model.monet_discriminator(fake_photo)\n        loss_G_XtoY = self.gan_loss(labeled_fake_monet, torch.ones_like(labeled_fake_monet))\n        loss_G_YtoX = self.gan_loss(labeled_fake_photo, torch.ones_like(labeled_fake_photo))\n\n        loss_cycle_XYX = self.cycle_loss(reconstructed_photo, real_photo)\n        loss_cycle_YXY = self.cycle_loss(reconstructed_monet, real_monet)\n\n        total_loss_G = loss_G_XtoY + loss_G_YtoX + loss_cycle_XYX + loss_cycle_YXY + loss_identity\n\n        total_loss_D_X = self.calculate_discriminator_loss(self.model.monet_discriminator, real_photo, fake_photo)\n\n        total_loss_D_Y = self.calculate_discriminator_loss(self.model.photo_discriminator, real_monet, fake_monet)\n\n        torch.cuda.empty_cache() # Attemting to clear cuda cache\n\n        return total_loss_G, total_loss_D_X, total_loss_D_Y\n\n    \n    def calculate_identity_loss(self, real_photo, real_monet):\n        identity_monet = self.model.monet_generator(real_monet)\n        identity_photo = self.model.photo_generator(real_photo)\n        loss_identity_monet = self.identity_loss(identity_monet, real_monet)\n        loss_identity_photo = self.identity_loss(identity_photo, real_photo)\n        total_loss = loss_identity_monet + loss_identity_photo\n        return total_loss\n\n    \n    def calculate_discriminator_loss(self, discriminator, real_item, fake_item):\n        item_labeled = discriminator(real_item.detach())\n        loss_real_item = self.gan_loss(item_labeled, torch.ones_like(item_labeled))\n        loss_fake_item = self.gan_loss(discriminator(fake_item.detach()), torch.zeros_like(item_labeled))\n        total_loss = (loss_real_item + loss_fake_item) / 2\n        return total_loss\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:22:48.896191Z","iopub.execute_input":"2023-12-12T02:22:48.896517Z","iopub.status.idle":"2023-12-12T02:22:48.909162Z","shell.execute_reply.started":"2023-12-12T02:22:48.896489Z","shell.execute_reply":"2023-12-12T02:22:48.908219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MonetTrainer:\n    def __init__(self, model:CycleGAN, epochs, lr, beta1, beta2, decay_epoch) -> None:\n        self.metrics = []\n        self.model = model\n        self.losses = MonetLoss(model)\n        self.epochs = epochs\n        self.init_optimizers(lr, beta1, beta2)\n        self.init_lr_schedulers(epochs, decay_epoch)\n\n  \n    def train_step(self, real_photo, real_monet):\n        real_photo = real_photo.type(Tensor)\n        real_monet = real_monet.type(Tensor)\n\n        # Generate fake images\n        fake_monet = self.model.monet_generator(real_photo)\n        fake_photo = self.model.photo_generator(real_monet)\n\n        # Cycle Consistency\n        reconstructed_X = self.model.photo_generator(fake_monet)\n        reconstructed_Y = self.model.monet_generator(fake_photo)\n\n        # Calculate losses\n        total_loss_G, total_loss_D_X, total_loss_D_Y = self.losses.calculate_loss(real_photo, real_monet, reconstructed_X, reconstructed_Y, fake_photo, fake_monet)\n\n        # Update generators\n        self.update_generators(total_loss_G)\n\n        # Update Discriminators\n        self.update_discriminators(total_loss_D_X, total_loss_D_Y)\n\n        torch.cuda.empty_cache() # Attemting to clear cuda cache\n        return total_loss_G, total_loss_D_X, total_loss_D_Y, fake_photo, fake_monet\n\n    \n    def update_generators(self, total_loss_G):\n        self.optimizer_G.zero_grad()\n        total_loss_G.backward()\n        self.optimizer_G.step()\n\n        \n    def update_discriminators(self, total_loss_D_X, total_loss_D_Y):\n        # Update Photo Discriminator\n        self.optimizer_D_X.zero_grad()\n        total_loss_D_X.backward()\n        self.optimizer_D_X.step()\n\n        # Update Monet Discriminator\n        self.optimizer_D_Y.zero_grad()\n        total_loss_D_Y.backward()\n        self.optimizer_D_Y.step()\n\n        \n    def train(self, dataloader, display_epoch: int=10):\n        # Training loop\n        for epoch in range(self.epochs):\n            self.train_epoch(dataloader, epoch, display_epoch)\n            self.update_lr_schedulers()\n\n            \n    def update_lr_schedulers(self):\n        self.lr_scheduler_G.step()\n        self.lr_scheduler_D_X.step()\n        self.lr_scheduler_D_Y.step()\n\n        \n    def train_epoch(self, dataloader, epoch, display_epoch):\n        for batch_idx, (real_photo, real_monet) in enumerate(dataloader):\n            real_photo, real_monet = real_photo.type(Tensor).detach(), real_monet.type(Tensor).detach()\n\n            total_loss_G, total_loss_D_X, total_loss_D_Y, fake_photo, fake_monet = self.train_step(real_photo, real_monet)\n\n            self.metrics.append({\n                    \"Epoch\": epoch,\n                    \"Batch\": batch_idx,\n                    \"Generator LR\": self.lr_scheduler_G.get_last_lr()[0],\n                    \"Discriminator X LR\": self.lr_scheduler_D_X.get_last_lr()[0],\n                    \"Discriminator Y LR\": self.lr_scheduler_D_Y.get_last_lr()[0],\n                    \"Generator Loss\": total_loss_G.item(),\n                    \"Discriminator X Loss\": total_loss_D_X.item(),\n                    \"Discriminator Y Loss\": total_loss_D_Y.item()  \n            })\n                \n            if batch_idx % display_epoch == 0:\n                self.show_metrics(dataloader)\n                \n            if epoch + 1 % display_epoch == 0:\n                MonetUtils.sample_images(real_photo, real_monet, fake_photo, fake_monet)\n                self.model.save_model(MODEL_CHECKPOINT)\n            \n            torch.cuda.empty_cache() # Attemting to clear cuda cache\n\n    def init_lr_schedulers(self, epochs, decay_epoch):\n        lr_lambda = lambda epoch: 1.0 - max(0, epoch - decay_epoch) / (epochs - decay_epoch)\n        self.lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(self.optimizer_G, lr_lambda=lr_lambda)\n        self.lr_scheduler_D_X = torch.optim.lr_scheduler.LambdaLR(self.optimizer_D_X, lr_lambda=lr_lambda)\n        self.lr_scheduler_D_Y = torch.optim.lr_scheduler.LambdaLR(self.optimizer_D_Y, lr_lambda=lr_lambda)\n\n        \n    def init_optimizers(self, lr, beta1, beta2):\n        self.optimizer_G = torch.optim.Adam(itertools.chain(self.model.monet_generator.parameters(), self.model.photo_generator.parameters()), lr=lr, betas=(beta1, beta2))\n        self.optimizer_D_X = torch.optim.Adam(self.model.monet_discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n        self.optimizer_D_Y = torch.optim.Adam(self.model.photo_discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n\n        \n    def show_metrics(self, dataloader):\n        latest_metrics = self.metrics[-1]\n\n        print(f'Epoch: {latest_metrics[\"Epoch\"]}/{self.epochs}, '\n                        f'Batch: {latest_metrics[\"Batch\"]}/{len(dataloader)}, '\n                        f'Generator LR: {latest_metrics[\"Generator LR\"]:.6f}, '\n                        f'Discriminator X LR: {latest_metrics[\"Discriminator X LR\"]:.6f}, '\n                        f'Discriminator Y LR: {latest_metrics[\"Discriminator Y LR\"]:.6f}, '\n                        f'Generator Loss: {latest_metrics[\"Generator Loss\"]:.4f}, '\n                        f'Discriminator X Loss: {latest_metrics[\"Discriminator X Loss\"]:.4f}, '\n                        f'Discriminator Y Loss: {latest_metrics[\"Discriminator Y Loss\"]:.4f}')\n        \n\n    def evaluate_fid(self, dataloader, batch_size=50, dims=2048):\n        os.makedirs(FID_SCORE_DIRS[0], exist_ok=True)\n        os.makedirs(FID_SCORE_DIRS[1], exist_ok=True)\n\n        self.model.monet_generator.eval()\n\n        with torch.no_grad():\n            for i, (real_images, _) in enumerate(dataloader):\n                fake_images = self.model.monet_generator(real_images.type(Tensor)).detach()\n\n                for j in range(real_images.size(0)):\n                    save_image(real_images[j], os.path.join(FID_SCORE_DIRS[0], f'real_{i * dataloader.batch_size + j}.png'))\n                    save_image(fake_images[j], os.path.join(FID_SCORE_DIRS[1], f'fake_{i * dataloader.batch_size + j}.png'))\n\n                if (i + 1) * dataloader.batch_size >= batch_size:\n                    break\n\n        fid = fid_score.calculate_fid_given_paths([FID_SCORE_DIRS[0], FID_SCORE_DIRS[1]], batch_size=batch_size, device=device, dims=dims)\n        return fid\n                  ","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:22:48.910442Z","iopub.execute_input":"2023-12-12T02:22:48.910719Z","iopub.status.idle":"2023-12-12T02:22:48.940342Z","shell.execute_reply.started":"2023-12-12T02:22:48.910694Z","shell.execute_reply":"2023-12-12T02:22:48.939377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MonetUtils:\n    @staticmethod\n    def sample_images(real_photo, real_monet, fake_photo, fake_monet):\n\n        real_photo = real_photo.type(Tensor)\n        fake_photo = fake_photo.type(Tensor)\n        real_monet = real_monet.type(Tensor)\n        fake_monet = fake_monet.type(Tensor)\n\n        ncols = real_photo.size(0)\n        real_photo_grid = make_grid(real_photo, nrow=ncols, normalize=True)\n        fake_monet_grid = make_grid(fake_monet, nrow=ncols, normalize=True)\n        real_monet_grid = make_grid(real_monet, nrow=ncols, normalize=True)\n        fake_photo_grid = make_grid(fake_photo, nrow=ncols, normalize=True)\n\n        fig, axs = plt.subplots(2, 2, figsize=(3*BATCH_SIZE, BATCH_SIZE))\n\n        axs[0, 0].imshow(real_photo_grid.permute(1, 2, 0).cpu().numpy())\n        axs[0, 0].set_title(\"Real Photos\")\n        axs[0, 0].axis('off')\n\n        axs[0, 1].imshow(fake_monet_grid.permute(1, 2, 0).cpu().numpy())\n        axs[0, 1].set_title(\"Generated Monet Arts from Photos\")\n        axs[0, 1].axis('off')\n\n        axs[1, 0].imshow(real_monet_grid.permute(1, 2, 0).cpu().numpy())\n        axs[1, 0].set_title(\"Real Monet Arts\")\n        axs[1, 0].axis('off')\n\n        axs[1, 1].imshow(fake_photo_grid.permute(1, 2, 0).cpu().numpy())\n        axs[1, 1].set_title(\"Generated Photos from Monet Arts\")\n        axs[1, 1].axis('off')\n\n        plt.tight_layout(h_pad=2.0, w_pad=1.0)\n        plt.show()\n\n    @staticmethod    \n    def transform(image_path, generator):\n        generator.eval()\n        image = Image.open(image_path).convert(\"RGB\")\n        image = transforms_dataset(image).unsqueeze(0).to(device)\n        with torch.no_grad():\n            output = generator(image).squeeze(0)\n        image = image.squeeze(0)    \n        return output, image\n    \n    def transform_to_monet(photo_path):\n        pass\n    \n    def transform_to_photo(painting_path):\n        pass\n    \n    \n    @staticmethod\n    def view_images(real_image, generate_image, title='Original and Generated Images'):\n        real_image = (real_image + 1) / 2\n        real_image = torch.clamp(real_image, 0, 1)\n        generate_image = (generate_image + 1) / 2\n        generate_image = torch.clamp(generate_image, 0, 1)\n        \n        grid = make_grid([real_image, generate_image])\n        grid = grid.permute(1, 2, 0).cpu().numpy()\n        \n        plt.figure(figsize=(5, 4))\n        plt.imshow(grid)\n        plt.title(title)\n        plt.axis('off')\n        plt.tight_layout(h_pad=0.0, w_pad=1.0)\n        plt.show()\n       \n    \n    @staticmethod\n    def make_submission():\n        os.makedirs(GENERATED_MONET_IMAGES, exist_ok=True)\n        start = time()\n\n        with zipfile.ZipFile(SUBMISSION_FILE, 'w', zipfile.ZIP_DEFLATED) as zipf:\n            for i, file_path in enumerate(TEST_IMAGES):\n                filename = os.path.basename(file_path)\n                output, _ = MonetUtils.transform_to_monet(file_path)\n                file_path = os.path.join(GENERATED_MONET_IMAGES, filename)\n                save_image(output, file_path)\n                zipf.write(file_path, filename)\n                \n                print(f\"Processed {i + 1}/{len(TEST_IMAGES)} - {round((i + 1)/len(TEST_IMAGES), 2)} %: {filename}  :: Time Elapsed: {int(time() - start)} Seconds\", end='\\r')\n\n        print(f\"\\nAll images processed and added to the zip file: {SUBMISSION_FILE}.\")\n    \n    \n    @staticmethod\n    def save_metrics(metrics):\n        with open(METRICS_FILE, \"w\", encoding=\"utf-8\") as jsonf:\n            json.dump(metrics, jsonf, indent=4)\n        \n        print(f\"\\nAll training metrics are in file: {METRICS_FILE}.\")\n\n\n    @staticmethod\n    def cleanup_jobs(target_dir, ext=\"*\"):\n        for f in glob.glob(f'{target_dir}/*.{ext}'):\n            os.remove(f)\n        \n        os.rmdir(target_dir)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:22:48.941574Z","iopub.execute_input":"2023-12-12T02:22:48.941894Z","iopub.status.idle":"2023-12-12T02:22:48.963292Z","shell.execute_reply.started":"2023-12-12T02:22:48.941867Z","shell.execute_reply":"2023-12-12T02:22:48.962364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading the datasets**","metadata":{}},{"cell_type":"code","source":"transforms_dataset = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])","metadata":{"id":"v0p6b2YN-IJz","execution":{"iopub.status.busy":"2023-12-12T02:22:48.964498Z","iopub.execute_input":"2023-12-12T02:22:48.964816Z","iopub.status.idle":"2023-12-12T02:22:48.976767Z","shell.execute_reply.started":"2023-12-12T02:22:48.964789Z","shell.execute_reply":"2023-12-12T02:22:48.975820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(\n    ImageDataset(test=False, transforms=transforms_dataset),\n    batch_size = BATCH_SIZE,\n    shuffle = True\n)\n\ntest_loader = DataLoader(\n    ImageDataset(test=True, transforms=transforms_dataset),\n    batch_size = BATCH_SIZE,\n    shuffle = False\n)","metadata":{"id":"9T0YO1BW-IJ5","execution":{"iopub.status.busy":"2023-12-12T02:22:48.978083Z","iopub.execute_input":"2023-12-12T02:22:48.978374Z","iopub.status.idle":"2023-12-12T02:22:48.986516Z","shell.execute_reply.started":"2023-12-12T02:22:48.978349Z","shell.execute_reply":"2023-12-12T02:22:48.985442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualize a photo example and a Monet painting example**","metadata":{"id":"zJJbiF8-JkE9"}},{"cell_type":"code","source":"# Load the last image from each dataset\nmonet_image_path = MONET_IMAGES[-1]\nphoto_image_path = TEST_IMAGES[-1]\nmonet_painting = transforms_dataset(Image.open(monet_image_path))\nexample_photo = transforms_dataset(Image.open(photo_image_path))\n\nMonetUtils.view_images(monet_painting, example_photo, 'Monet Painting and Photo Example')","metadata":{"id":"5FvQqfa0lm8B","outputId":"8b66a8f7-3ca3-4ece-aa94-2438568f1cb3","execution":{"iopub.status.busy":"2023-12-12T02:22:48.987733Z","iopub.execute_input":"2023-12-12T02:22:48.988086Z","iopub.status.idle":"2023-12-12T02:22:49.303461Z","shell.execute_reply.started":"2023-12-12T02:22:48.988057Z","shell.execute_reply":"2023-12-12T02:22:49.302496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Compile CycleGAN class**","metadata":{"id":"TMjg5JRGSHek"}},{"cell_type":"code","source":"cyclegan = CycleGAN(3)","metadata":{"id":"cbO5AfLxmZOh","execution":{"iopub.status.busy":"2023-12-12T02:22:49.305264Z","iopub.execute_input":"2023-12-12T02:22:49.305643Z","iopub.status.idle":"2023-12-12T02:22:51.145123Z","shell.execute_reply.started":"2023-12-12T02:22:49.305610Z","shell.execute_reply":"2023-12-12T02:22:51.144284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from functools import partial\n\nMonetUtils.transform_to_monet = partial(MonetUtils.transform, generator=cyclegan.monet_generator)\nMonetUtils.transform_to_photo = partial(MonetUtils.transform, generator=cyclegan.photo_generator)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:22:51.146295Z","iopub.execute_input":"2023-12-12T02:22:51.146604Z","iopub.status.idle":"2023-12-12T02:22:51.151871Z","shell.execute_reply.started":"2023-12-12T02:22:51.146577Z","shell.execute_reply":"2023-12-12T02:22:51.150783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_X, real_Y = next(iter(test_loader))","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:22:51.153453Z","iopub.execute_input":"2023-12-12T02:22:51.153987Z","iopub.status.idle":"2023-12-12T02:22:51.186382Z","shell.execute_reply.started":"2023-12-12T02:22:51.153920Z","shell.execute_reply":"2023-12-12T02:22:51.185374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Print Sample Before Training\nfake_Y, fake_X = cyclegan.forward(real_X.type(Tensor), real_Y.type(Tensor))\nMonetUtils.sample_images(real_X, real_Y, fake_X, fake_Y)\ncyclegan.save_model(MODEL_CHECKPOINT)\ntorch.cuda.empty_cache()","metadata":{"id":"0tMDtxPRSmju","outputId":"5269164f-e3d8-4bcf-fc5f-2d284cb68117","execution":{"iopub.status.busy":"2023-12-12T02:22:51.187907Z","iopub.execute_input":"2023-12-12T02:22:51.188653Z","iopub.status.idle":"2023-12-12T02:22:53.617775Z","shell.execute_reply.started":"2023-12-12T02:22:51.188611Z","shell.execute_reply":"2023-12-12T02:22:53.616909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fake_, real_ = MonetUtils.transform_to_monet(photo_image_path)\nMonetUtils.view_images(real_, fake_, \"Original Photo and It's Generated Art\")\nfake_, real_ = MonetUtils.transform_to_photo(monet_image_path)\nMonetUtils.view_images(real_, fake_, \" Monet Art and It's Generated Photo\")","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:22:53.618882Z","iopub.execute_input":"2023-12-12T02:22:53.619186Z","iopub.status.idle":"2023-12-12T02:22:54.024952Z","shell.execute_reply.started":"2023-12-12T02:22:53.619158Z","shell.execute_reply":"2023-12-12T02:22:54.024002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training on Entire Data Set**","metadata":{"id":"uqyQl6s362yp"}},{"cell_type":"code","source":"trainer = MonetTrainer(cyclegan, n_epoches, lr, beta1, beta2, decay_epoch)","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:22:54.026178Z","iopub.execute_input":"2023-12-12T02:22:54.026486Z","iopub.status.idle":"2023-12-12T02:22:54.032702Z","shell.execute_reply.started":"2023-12-12T02:22:54.026459Z","shell.execute_reply":"2023-12-12T02:22:54.031794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train(train_loader)\ntorch.cuda.empty_cache()","metadata":{"id":"Vl3vtMgH69FU","outputId":"8e562ee7-a0b7-41ff-d0a2-147705f074ee","execution":{"iopub.status.busy":"2023-12-12T02:23:07.177931Z","iopub.execute_input":"2023-12-12T02:23:07.178852Z","iopub.status.idle":"2023-12-12T02:26:06.079148Z","shell.execute_reply.started":"2023-12-12T02:23:07.178817Z","shell.execute_reply":"2023-12-12T02:26:06.077047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualizing the Solution**","metadata":{}},{"cell_type":"code","source":"#Print Sample After Model Training\nfake_Y, fake_X = cyclegan.forward(real_X.type(Tensor), real_Y.type(Tensor))\nMonetUtils.sample_images(real_X, real_Y, fake_X, fake_Y)\ncyclegan.save_model(SAVED_MODEL_PATH)\ntorch.cuda.empty_cache()","metadata":{"id":"F20WZ1dz7gO7","execution":{"iopub.status.busy":"2023-12-12T02:26:19.467737Z","iopub.execute_input":"2023-12-12T02:26:19.468515Z","iopub.status.idle":"2023-12-12T02:26:21.126445Z","shell.execute_reply.started":"2023-12-12T02:26:19.468477Z","shell.execute_reply":"2023-12-12T02:26:21.125359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fake_, real_ = MonetUtils.transform_to_monet(photo_image_path)\nMonetUtils.view_images(real_, fake_, \"Original Photo and It's Generated Art\")\nfake_, real_ = MonetUtils.transform_to_photo(monet_image_path)\nMonetUtils.view_images(real_, fake_, \" Monet Art and It's Generated Photo\")","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:26:30.108063Z","iopub.execute_input":"2023-12-12T02:26:30.108457Z","iopub.status.idle":"2023-12-12T02:26:30.533548Z","shell.execute_reply.started":"2023-12-12T02:26:30.108423Z","shell.execute_reply":"2023-12-12T02:26:30.532613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TO TESTING PRE-TRAINED MODEL**","metadata":{}},{"cell_type":"markdown","source":"**Evaluating the model using FID Score**","metadata":{}},{"cell_type":"code","source":"score = trainer.evaluate_fid(test_loader)\nprint(f'FID Score: {score}')","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:26:39.623425Z","iopub.execute_input":"2023-12-12T02:26:39.623827Z","iopub.status.idle":"2023-12-12T02:26:54.578013Z","shell.execute_reply.started":"2023-12-12T02:26:39.623795Z","shell.execute_reply":"2023-12-12T02:26:54.573819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create Submission Images**","metadata":{}},{"cell_type":"code","source":"MonetUtils.make_submission()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Trigger Download Link**","metadata":{}},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(SUBMISSION_FILE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Save Training Metrics**","metadata":{}},{"cell_type":"code","source":"MonetUtils.save_metrics(trainer.metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Clean Up (Optional)**","metadata":{}},{"cell_type":"code","source":"[MonetUtils.cleanup_jobs(folder) for folder in FID_SCORE_DIRS + [GENERATED_MONET_IMAGES]]","metadata":{"execution":{"iopub.status.busy":"2023-12-12T02:27:15.430812Z","iopub.execute_input":"2023-12-12T02:27:15.431705Z","iopub.status.idle":"2023-12-12T02:27:15.522041Z","shell.execute_reply.started":"2023-12-12T02:27:15.431667Z","shell.execute_reply":"2023-12-12T02:27:15.520786Z"},"trusted":true},"execution_count":null,"outputs":[]}]}